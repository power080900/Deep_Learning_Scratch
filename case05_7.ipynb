{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba3f7bd-f475-46b6-96db-e2c89323c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from dataset.util import *\n",
    "from dataset.util import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ecb61e-f62f-46ee-a4de-5303f738ce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:8.770685639963195e-05\n",
      "b1:0.0006707444296544385\n",
      "W2:0.003010104209787678\n",
      "b2:0.06666666678634872\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) =  load_mnist(normalize=True, one_hot_label=True)\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key+':'+str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ac6d9b-f7f8-435b-a4b2-314b1d1af42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) =  load_mnist(normalize=True, one_hot_label=True)\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_late = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73bd24be-b320-4f4a-965f-c2c9bb9123d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15151666666666666 0.1575\n",
      "0.09871666666666666 0.098\n",
      "0.10218333333333333 0.101\n",
      "0.09871666666666666 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\lee\\study\\Deep_Learning_Scratch\\dataset\\util.py:102: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_a = np.exp(a-c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n",
      "0.09871666666666666 0.098\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      9\u001b[0m     network\u001b[38;5;241m.\u001b[39mparams[key] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_late\u001b[38;5;241m*\u001b[39mgrad[key]\n\u001b[1;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m iter_per_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\lee\\study\\Deep_Learning_Scratch\\dataset\\util.py:242\u001b[0m, in \u001b[0;36mTwoLayerNet.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m--> 242\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastLayer\u001b[38;5;241m.\u001b[39mforward(y,t)\n",
      "File \u001b[1;32mC:\\lee\\study\\Deep_Learning_Scratch\\dataset\\util.py:231\u001b[0m, in \u001b[0;36mTwoLayerNet.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m--> 231\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m#         W1, W2 = self.params['W1'], self.params['W2']\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m#         b1, b2 = self.params['b1'], self.params['b2']\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m#         a2 = np.dot(z1,W2) + b2\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m#         y = softmax(a2)\u001b[39;00m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mC:\\lee\\study\\Deep_Learning_Scratch\\dataset\\util.py:56\u001b[0m, in \u001b[0;36mAffine.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 56\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_late*grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0211e-cd68-40b6-8f04-c62de5ddb4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
